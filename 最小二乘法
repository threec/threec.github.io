  最近在看推荐系统相关的文章，习惯了在收藏夹中收藏网址，最后发现查找起来还是繁琐，索性花点时间将读来的资料整理一下好了，一来加强自
  己的理解，二来以后也能用来复习，文中所述内容多来自他人博客，偶有自我见解。
    在我们研究两个变量(x, y)之间的相互关系时，通常可以得到一系列成对的数据(x1, y1、x2, y2... xm , ym)；将这些数据描绘在x -y直角座标系中(如图1), 若发现这些点在一条直线附近，可以令这条直线方程如(式1-1)。 

Y计= a0 + a1 X 　　　　　　　　　　　　　　　　　　　(式1-1) 
其中：a0、a1 是任意实数 
为建立这直线方程就要确定a0和a1，应用《最小二乘法原理》，将实测值Yi与利用(式1-1)计算值(Y计=　a0　+　a1　X)的离差(Yi　-　Y计)的平方和｀〔∑(Yi - Y计)2〕最小为“优化判据”。 
令: φ = ∑(Yi - Y计)2 　　　　　　　　　　　　　　　(式1-2) 
把(式1-1)代入(式1-2)中得: 
φ = ∑(Yi - a0 - a1 Xi)2 　　　　　　　　　　　　　(式1-3) 
当∑(Yi-Y计)平方最小时，可用函数 φ 对a0、a1求偏导数，令这两个偏导数等于零。 
　　　　　　　　　　(式1-4) 
　　　　　　　　　(式1-5) 　
亦即： 
m a0 + (∑Xi ) a1 = ∑Yi 　　　　　　　　　　　　　　(式1-6) 
(∑Xi ) a0 + (∑Xi2 ) a1 = ∑(Xi, Yi) 　　　　　　　　(式1-7) 
得到的两个关于a0、 a1为未知数的两个方程组，解这两个方程组得出：
a0 = (∑Yi) / m - a1(∑Xi) / m (式1-8)
a1 = [∑Xi Yi - (∑Xi ∑Yi)/ m] / [∑Xi2 - (∑Xi)2 / m)] 　　(式1-9) 
这时把a0、a1代入(式1-1)中, 此时的(式1-1)就是我们回归的元线性方程即：数学模型。 
在回归过程中，回归的关联式是不可能全部通过每个回归数据点(x1, y1、 x2, y2...xm,ym),为了判断关联式的好坏,可借助相关系数“R”，统计量“F”，剩余标准偏差“S”进行判断；“R”越趋近于 1 越好；“F”的绝对值越大越好；“S”越趋近于 0 越好。 
R = [∑XiYi - m (∑Xi / m)(∑Yi / m)]/ SQR{[∑Xi2 - m (∑Xi / m)2][∑Yi2 - m (∑Yi / m)2]} 　　　　　　　(式1-10) ＊
在(式1-1)中，m为样本容量，即实验次数；Xi、Yi分别任意一组实验X、Y的数值。

返回页首

  最小三乘法

当研究实际中两个变量(x, y)之间的相互关系时，也可得到一系列成对的数据(x1,y1、x2,y2 ... xm,ym)；将这些数据描绘在x - y直 角座标系(如图2)中,发现这些点在一条曲线附近，假设这条曲线的一元非线性方程如(式2-1)。

Y计 = a0 + a1 Xk 　　　　　　　　　　　(式2-1) 
其中：a0、a1、k是任意实数 
为建立曲线方程，就要确定a0 、a1和 k 值，应用《最小二乘法》同样的方法, 将实测值Yi与计算值 Y计（Y计　= a0 + a1 Xik）的离差 (Yi - Y计)的平方和〔∑(Yi - Y计)2〕为依据：
令: φ = ∑(Yi - Y计)2 　　　　　　　　　　(式2-2)
把(式2-1)代入(式2-2)中得：
φ = ∑(Yi - a0 - a1 Xik )2 　　　　　　(式2-3) 
用函数 φ 分别对a0、a1 和 k 求偏导数，令这三个偏导数等于零即：
　　　　　(式2-4) 
　　　　　(式2-5) 
　　　(式2-6) 
得到三个关于a0、a1 和 k，为未知数的三元方程组，解方程组即可得到数学模型。 
判断数学模型的好坏，同样可借助相关系数“R”，统计量“F” ，剩余标准偏差“S”进行判断；“R”越趋近于 1 越好；“F”的绝对值越大越好；“S”越趋近于 0 越好。这样的验证很好时，有的模型计算误差还是很大，为了更进一步的验证数学模型，必需计算模型的最大误差、平均误差和平均相对误差来验证模型。

返回页首

 最小三乘法和最小二乘法比较

若对任意曲线用(式3-1) 拟和 
　　Y计 = a0 + a1 XK 　　　　　　　　(式3-1)  
　“最小二乘法”和“最小三乘法”比较表：
　	最小二乘法	最小三乘法
  拟和式：	Y计 = a0 + a1 Xk	Y计 = a0 + a1 Xk
优化判据：	∑(Yi - Y计)2	∑(Yi - Y计)2
回归计算结果：	a0 和 a1， k = 1（默认）	a0 、a1　和 　k
通过比较，“最小二乘法”和“最小三乘法”的“优化判据”[∑( Yi - Y计)2 ] 相同，“最小三乘法”计算了因变量的幂值　k ，“最小二乘法”不计算因变量的幂值 k ，把它默认为 1 。 
1．“最小三乘法”利用计算幂值，使回归模型函数曲线以不同曲率弯曲，来更好的拟和不同曲率的曲线。它省去了“最小二乘法”中繁琐的建机理模型和线性化处理，使回归模型与数据拟和更好。
2．对多维非线性数据回归，不用“偏最小二乘法”的每因素逐一与目标函数回归建模，再把所有模型捆绑成最终模型的方法，而是所有因素与目标函数，同时一次回归成数学模型，在回归时，它不但考虑因素对目标函数的贡献，还把因素之间的影响考虑进去，这样的模型要比用“偏最小二乘法”回归的模型准确。
3．“最小二乘法”数据回归一因素数据只有一元 “X”， “最小三乘法” 数据回归一因素数据可有若干个元“Xk1”、“Xk2” 、… “Xkn” 如(式3-2)， 利用这一特性，可使回归模型拟和数据更准确。 
Y计 = a0 + a1 Xk1 + a2 Xk2 +...+ an X kn            　　     (式3-2)

返回页首

　模型选择

一、机理研究法 
机理研究法是研究某过程的内在联系，对过程假设后，而建立的两个或两个以上因素之间关系的数学方程式；对数学方程式做数学变形处理，找出与预设模型(数学方程式)相对应的元和目标函数，在利用数据回归计算机理模型的系数。 
二、数据研究法 
数据研究法是对两维数据，以两维数据分别为目标函数和因素，因素 X 的变化引起目标函数 Y 变化，这种变化可分为六种情况如(图3-1)—(图3-6)。 

第一种 线性增加，随因素 X 增加，因素 Y 匀速增大。 
第二种 线性减少，随因素 X 增加，因素 Y 匀速减小。 
第三种 非线性增加，随因素 X 增加，因素 Y 加速增大。 
第四种 非线性增加，随因素 X 增加，因素 Y 减速增大。 
第五种 非线性减少，随因素 X 增加，因素 Y 加速减小。
第六种 非线性减少，随因素 X 增加，因素 Y 减速减小。 
假设此六种情况方程式为： 
Y = a0 + a1 Xk 　　　　　　(式4-1)
第一种情况显然 a0 > 0 时，a1 ＞ 0、k ＝ 1 
第二种情况显然 a0 > 0 时，a1 ＜ 0、k ＝ 1
第三种情况显然 a0 > 0 时，a1 ＞ 0、k ＞ 1、k ＜ 0 
第四种情况显然 a0 > 0 时，a1 ＞ 0、0 ＜ k ＜ 1 
第五种情况显然 a0 > 0 时，a1 ＜ 0、0 ＜ k ＜ 1 
第六种情况显然 a0 > 0 时，a1 ＜ 0、k ＞ 1、 k ＜ 0
通过上述分析总结，确定回归参数(即每一元)的数学式，第三、六种情况，曲线上凹，与指数曲线相似，可选指数形式 eX ； 第四、五种情况，曲线上凸，与对数形式相似，可选对数形式 LOG(X)(对数底为e)；若选择幂形式 Xk，可根据上述第一种情况至第六种情况中 a0、a1、a2 和 k 之间的关系选择 k 值。
三、选择回归参数注意问题 
1、当一因素数据中有 0 值时， 此因素数据不可作除数和取对数；可把此维数据加上一个数，使它大于零。 
2、当一因素数据中有负数都有时，此因素数据不可做回归计算；可把此维数据乘上一个负数，使它大于零。 
3、某因素数据取幂时，不可太大和太小，否则回归计算机会中断溢出；有时回归出的模型，不能逆运算。
